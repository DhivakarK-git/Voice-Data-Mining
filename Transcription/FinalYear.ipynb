{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7457ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "\n",
    "# For managing audio file\n",
    "import librosa\n",
    "\n",
    "#Importing Pytorch\n",
    "import torch\n",
    "\n",
    "from jiwer import wer\n",
    "\n",
    "#Importing Wav2Vec tokenizer\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "warnings.warn = ignore_warn\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04677ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_960h_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\",cache_dir=\"D:\\\\Study\\\\Sem7\\\\Final Year\\\\cache\\\\models\\\\base-960h\")\n",
    "base_960h_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\",cache_dir=\"D:\\\\Study\\\\Sem7\\\\Final Year\\\\cache\\\\models\\\\base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f434a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "display.Audio(\"D:/BraveDownloads/taken_clip.wav\", autoplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592233c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the audio file\n",
    "\n",
    "audio, rate = librosa.load(\"D:/BraveDownloads/taken_clip.wav\", sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f5f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf4aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fabadf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = base_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a503ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing logits (non-normalized prediction values)\n",
    "with torch.no_grad():\n",
    "    logits = base_960h_model(input_values).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163565e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing predicted id's\n",
    "prediction = torch.argmax(logits, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bc0c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transcription = base_960h_processor.batch_decode(prediction)[0]\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6cb848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c2894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "display.Audio(\"D:/BraveDownloads/Jordan Peterson Confronts Australian Politician on Gender Politics and Quotas _ Q&A.wav\", autoplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b65c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the audio file\n",
    "\n",
    "audio, rate = librosa.load(\"D:/BraveDownloads/Jordan Peterson Confronts Australian Politician on Gender Politics and Quotas _ Q&A.wav\", sr = 16000, offset=100.0, duration=30.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a90d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3377e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04007668",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = base_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing logits (non-normalized prediction values)\n",
    "with torch.no_grad():\n",
    "    logits = base_960h_model(input_values).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128b5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing predicted id's\n",
    "prediction = torch.argmax(logits, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38920ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transcription = base_960h_processor.batch_decode(prediction)[0]\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "from os.path import join\n",
    "path='D:/BraveDownloads/temp/temp'\n",
    "filenames = next(walk(path), (None, None, []))[2]\n",
    "filenames=[path+'/'+f for f in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755e3985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in filenames:\n",
    "    audio, rate = librosa.load(file, sr = 16000)\n",
    "    input_values = base_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "    print(\"\\n\",file)\n",
    "    with torch.no_grad():\n",
    "        logits = base_960h_model(input_values).logits\n",
    "    prediction = torch.argmax(logits, dim = -1)\n",
    "    transcription = base_960h_processor.batch_decode(prediction)[0]\n",
    "    print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca30009",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/record.wav\", sr = 16000)\n",
    "input_values = base_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "print(\"\\n\",file)\n",
    "with torch.no_grad():\n",
    "    logits = base_960h_model(input_values).logits\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = base_960h_processor.batch_decode(prediction)[0]\n",
    "print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bea967",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/record (1).wav\", sr = 16000)\n",
    "input_values = base_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = base_960h_model(input_values).logits\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = base_960h_processor.batch_decode(prediction)[0]\n",
    "print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/record (2).wav\", sr = 16000)\n",
    "input_values = base_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "with torch.no_grad():    \n",
    "    logits = base_960h_model(input_values).logits\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = base_960h_processor.batch_decode(prediction)[0]\n",
    "print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed85d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/NDTV Exclusive - Rahul Gandhi's First TV Interview This Election Season.wav\", sr = 16000, duration=30.0)\n",
    "input_values = base_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "with torch.no_grad():\n",
    "    logits = base_960h_model(input_values).logits\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = base_960h_processor.batch_decode(prediction)[0]\n",
    "print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250633cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "s21_small_model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\",cache_dir=\"D:\\\\Study\\\\Sem7\\\\Final Year\\\\cache\\\\models\\\\s21-small\")\n",
    "s21_small_processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\",cache_dir=\"D:\\\\Study\\\\Sem7\\\\Final Year\\\\cache\\\\models\\\\s21-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa0ce4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\",cache_dir=\"D:\\\\Study\\\\Sem7\\\\Final Year\\\\cache\\\\datasets\\\\lad\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c176ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(map_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94225346",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = s21_small_processor(ds[\"speech\"][0], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "generated_ids = s21_small_model.generate(input_ids=inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"])\n",
    "transcription = s21_small_processor.batch_decode(generated_ids)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91b3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a7977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/NDTV Exclusive - Rahul Gandhi's First TV Interview This Election Season.wav\", sr = 16000, duration=30.0)\n",
    "inputs = s21_small_processor(audio, sampling_rate=16_000, return_tensors=\"pt\")\n",
    "generated_ids = s21_small_model.generate(input_ids=inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"])\n",
    "transcription = s21_small_processor.batch_decode(generated_ids)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e2848",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc9c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/Jordan Peterson Confronts Australian Politician on Gender Politics and Quotas _ Q&A.wav\", sr = 16000, offset=100.0, duration=30.0)\n",
    "inputs = s21_small_processor(audio, sampling_rate=16_000, return_tensors=\"pt\")\n",
    "generated_ids = s21_small_model.generate(input_ids=inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"])\n",
    "transcription = s21_small_processor.batch_decode(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_960h_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\",cache_dir=\"D:\\\\Study\\\\Sem7\\\\Final Year\\\\cache\\\\models\\\\large-960h\")\n",
    "large_960h_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\",cache_dir=\"D:\\\\Study\\\\Sem7\\\\Final Year\\\\cache\\\\models\\\\large-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2475841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/NDTV Exclusive - Rahul Gandhi's First TV Interview This Election Season.wav\", sr = 16000, duration=30.0)\n",
    "input_values = large_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "with torch.no_grad():\n",
    "    logits = large_960h_model(input_values).logits\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = large_960h_processor.batch_decode(prediction)[0]\n",
    "print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/Jordan Peterson Confronts Australian Politician on Gender Politics and Quotas _ Q&A.wav\", sr = 16000, offset=100.0, duration=30.0)\n",
    "input_values = large_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "with torch.no_grad():\n",
    "    logits = large_960h_model(input_values).logits\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = large_960h_processor.batch_decode(prediction)[0]\n",
    "print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bea746",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/record (1).wav\", sr = 16000)\n",
    "input_values = large_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "with torch.no_grad():\n",
    "    logits = large_960h_model(input_values).logits\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = large_960h_processor.batch_decode(prediction)[0]\n",
    "print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda58130",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/record (2).wav\", sr = 16000)\n",
    "input_values = large_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "with torch.no_grad():\n",
    "    logits = large_960h_model(input_values).logits\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = large_960h_processor.batch_decode(prediction)[0]\n",
    "print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_960h_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\",cache_dir=\"D:\\\\Study\\\\Sem7\\\\Final Year\\\\cache\\\\models\\\\pro-960h\")\n",
    "pro_960h_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\",cache_dir=\"D:\\\\Study\\\\Sem7\\\\Final Year\\\\cache\\\\models\\\\pro-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed11d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/record (2).wav\", sr = 16000)\n",
    "input_values = pro_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "with torch.no_grad():\n",
    "    logits = pro_960h_model(input_values).logits\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = pro_960h_processor.batch_decode(prediction)[0]\n",
    "print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3019dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/Jordan Peterson Confronts Australian Politician on Gender Politics and Quotas _ Q&A.wav\", sr = 16000, offset=100.0, duration=30.0)\n",
    "input_values = pro_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "with torch.no_grad():\n",
    "    logits = pro_960h_model(input_values).logits\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = pro_960h_processor.batch_decode(prediction)[0]\n",
    "print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952caa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/record (1).wav\", sr = 16000)\n",
    "input_values = pro_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "with torch.no_grad():\n",
    "    logits = pro_960h_model(input_values).logits\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = pro_960h_processor.batch_decode(prediction)[0]\n",
    "print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7666dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/record.wav\", sr = 16000)\n",
    "input_values = pro_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "with torch.no_grad():\n",
    "    logits = pro_960h_model(input_values).logits\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = pro_960h_processor.batch_decode(prediction)[0]\n",
    "print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424defca",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/NDTV Exclusive - Rahul Gandhi's First TV Interview This Election Season.wav\", sr = 16000, duration=30.0)\n",
    "input_values = pro_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "with torch.no_grad():\n",
    "    logits = pro_960h_model(input_values).logits\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = pro_960h_processor.batch_decode(prediction)[0]\n",
    "print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654e467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in filenames:\n",
    "    audio, rate = librosa.load(file, sr = 16000)\n",
    "    input_values = pro_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "    print(\"\\n\",file)\n",
    "    with torch.no_grad():\n",
    "        logits = pro_960h_model(input_values).logits\n",
    "    prediction = torch.argmax(logits, dim = -1)\n",
    "    transcription = pro_960h_processor.batch_decode(prediction)[0]\n",
    "    print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a0344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/record.wav\", sr = 16000)\n",
    "input_values = pro_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d026f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():    \n",
    "    logits = pro_960h_model(input_values).logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.argmax(logits, dim = -1)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f453543",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = pro_960h_processor.batch_decode(prediction)[0]\n",
    "print('\\n',transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastpunct import FastPunct\n",
    "# The default language is 'english'\n",
    "fastpunct = FastPunct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6105a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastpunct.punct([\n",
    "                \"john smiths dog is creating a ruccus\",\n",
    "                \"ys jagan is the chief minister of andhra pradesh\",\n",
    "                 \"we visted new york last year in may\"\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd459907",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastpunct.punct(transcription.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81e053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"D:/BraveDownloads/Jordan Peterson Confronts Australian Politician on Gender Politics and Quotas _ Q&A.wav\", sr = 16000, offset=100.0, duration=30.0)\n",
    "input_values = pro_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\",sampling_rate=rate).input_values\n",
    "with torch.no_grad():\n",
    "    logits = pro_960h_model(input_values).logits\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "transcription = pro_960h_processor.batch_decode(prediction)[0].lower()\n",
    "print('\\n',transcription,\"\\n\")\n",
    "print(fastpunct.punct(transcription))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95909b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fastpunct.punct([transcription],correct=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7677639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained('t5-base',cache_dir=\"D:\\\\Study\\\\Sem7\\\\Final Year\\\\cache\\\\models\\\\t5\")\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-base',cache_dir=\"D:\\\\Study\\\\Sem7\\\\Final Year\\\\cache\\\\models\\\\t5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d5f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My name parth and want to become data scientist.\" ##Incorrect Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552513ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8edc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"%s </s>\" % (text)\n",
    "\n",
    "\n",
    "max_len = 128\n",
    "\n",
    "encoding = t5_tokenizer.encode_plus(text, return_tensors=\"pt\")\n",
    "input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b05fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decoding (inp_ids,attn_mask):\n",
    "    greedy_output = t5_model.generate(input_ids=inp_ids, attention_mask=attn_mask, max_length=128)\n",
    "    Question =  t5_tokenizer.decode(greedy_output[0], skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "    return Question.strip().capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79deb75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Incorrect: \",text)\n",
    "\n",
    "output = greedy_decoding(input_ids,attention_masks)\n",
    "print (\"\\nCorrect: \",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad67b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gingerit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gingerit.gingerit import GingerIt\n",
    "\n",
    "text = 'The smelt of fliwers bring back memories.'\n",
    "\n",
    "parser = GingerIt()\n",
    "parser.parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7964ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.parse(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3914ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fastpunct.punct([parser.parse(transcription)['result']],correct=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9038f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.parse(transcription)['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fca06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b6880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from punctuator import Punctuator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Punctuator('D:/Study/Sem7/Final Year/.punctuator/Demo-Europarl-EN.pcl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.punctuate(transcription))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef0b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.punctuate(parser.parse(transcription)['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514001c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "librispeech_eval = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\",cache_dir=\"D:\\\\Study\\\\Sem7\\\\Final Year\\\\cache\\\\datasets\\\\lad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565bb38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[[base_960h_processor,base_960h_model,\"facebook/wav2vec2-base-960h\"],[large_960h_processor,large_960h_model,\"facebook/wav2vec2-large-960h\"],[pro_960h_processor,pro_960h_model,\"facebook/wav2vec2-large-960h-lv60-self\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo=[s21_small_processor,s21_small_model,\"facebook/s2t-small-librispeech-asr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "librispeech_eval = librispeech_eval.map(map_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "librispeech_eval.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ae1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    def map_to_pred(batch):\n",
    "        input_values = model[0](batch[\"speech\"], sampling_rate=16000, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "        with torch.no_grad():\n",
    "            logits = model[1](input_values).logits\n",
    "\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = model[0].batch_decode(predicted_ids)\n",
    "        batch[\"transcription\"] = transcription\n",
    "        return batch\n",
    "\n",
    "    result = librispeech_eval.map(map_to_pred, batched=True, batch_size=1, remove_columns=[\"speech\"])\n",
    "\n",
    "    print(model[2],\"WER:\", wer(result[\"text\"], result[\"transcription\"]))\n",
    "    \n",
    "def map_to_pred(batch):\n",
    "    inputs = s21_small_processor(ds[\"speech\"][0], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "    generated_ids = s21_small_model.generate(input_ids=inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"])\n",
    "    transcription = s21_small_processor.batch_decode(generated_ids)\n",
    "    batch[\"transcription\"] = transcription\n",
    "    return batch\n",
    "\n",
    "result = librispeech_eval.map(map_to_pred, batched=True, batch_size=1, remove_columns=[\"speech\"])\n",
    "\n",
    "print(modelo[2],\"WER:\", wer(result[\"text\"], result[\"transcription\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0558277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "wav_fpath = Path(\"D:/BraveDownloads/Jordan Peterson Confronts Australian Politician on Gender Politics and Quotas _ Q&A.wav\")\n",
    "afile = {'audio': \"D:/BraveDownloads/Jordan Peterson Confronts Australian Politician on Gender Politics and Quotas _ Q&A.wav\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ccb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio.features import RawAudio\n",
    "\n",
    "# load audio waveform and play it\n",
    "waveform = RawAudio(sample_rate=16000)(afile).data\n",
    "display.Audio(data=waveform.squeeze(), rate=16000, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7812d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = torch.hub.load('pyannote/pyannote-audio', 'dia')\n",
    "diarization = pipeline(afile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc9844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(diarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a3265",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diarization.itertracks():\n",
    "    print(dir(i[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f232d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in diarization.itertracks():\n",
    "    audio, rate = librosa.load(\"D:/BraveDownloads/Jordan Peterson Confronts Australian Politician on Gender Politics and Quotas _ Q&A.wav\", sr = 16000, offset=i[0].start, duration=i[0].end-i[0].start)\n",
    "    input_values = pro_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\", sampling_rate=rate).input_values\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            logits = pro_960h_model(input_values).logits\n",
    "        prediction = torch.argmax(logits, dim = -1)\n",
    "        transcription = pro_960h_processor.batch_decode(prediction)[0].lower()\n",
    "        print('\\n',transcription)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio.utils.signal import Peak\n",
    "scd = torch.hub.load('pyannote/pyannote-audio', 'scd_ami')\n",
    "peak = Peak(alpha=0.10, min_duration=0.10, log_scale=True)\n",
    "scd_scores = scd(afile)\n",
    "# speaker change point (as `pyannote.core.Timeline` instance)\n",
    "partition = peak.apply(scd_scores, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce03cd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in dir(partition):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474817ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in partition.segments_list_:\n",
    "    audio, rate = librosa.load(\"D:/BraveDownloads/Jordan Peterson Confronts Australian Politician on Gender Politics and Quotas _ Q&A.wav\", sr = 16000, offset=i.start, duration=i.end-i.start)\n",
    "    input_values = pro_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\", sampling_rate=rate).input_values\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            logits = pro_960h_model(input_values).logits\n",
    "        prediction = torch.argmax(logits, dim = -1)\n",
    "        transcription = pro_960h_processor.batch_decode(prediction)[0].lower()\n",
    "        print(\"\\\"\"+transcription+\"\\\"\" if transcription != None else \"[NOISE]\")\n",
    "    except:\n",
    "        print(\"[NOISE]\")\n",
    "        continue \n",
    "    display.display(display.Audio(data=audio.squeeze(), rate=16000, autoplay=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in partition.segments_list_:\n",
    "    print(i.start,i.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f6a7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sad = torch.hub.load('pyannote/pyannote-audio', 'sad_ami')\n",
    "sad_scores = sad(afile)\n",
    "\n",
    "# binarize raw SAD scores\n",
    "# NOTE: both onset/offset values were tuned on AMI dataset.\n",
    "# you might need to use different values for better results.\n",
    "from pyannote.audio.utils.signal import Binarize\n",
    "binarize = Binarize(offset=0.52, onset=0.52, log_scale=True, \n",
    "                    min_duration_off=0.1, min_duration_on=0.1)\n",
    "\n",
    "# speech regions (as `pyannote.core.Timeline` instance)\n",
    "speech = binarize.apply(sad_scores, dimension=1)\n",
    "\n",
    "emb = torch.hub.load('pyannote/pyannote-audio', 'emb_ami')\n",
    "speech_turns = partition.crop(speech)\n",
    "embeddings = emb(afile)\n",
    "chunks = embeddings.sliding_window\n",
    "print(f'Embeddings were extracted every {1000 * chunks.step:g}ms on {1000 * chunks.duration:g}ms-long windows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc828d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2c0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_turns.segmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(diarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962f6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization.label_timeline('A').segments_list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0764af",
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization.label_timeline('B').segments_list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc7682",
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23391cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spectralcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b738952",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9579ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectralcluster import SpectralClusterer\n",
    "\n",
    "clusterer = SpectralClusterer(\n",
    "    min_clusters=2,\n",
    "    max_clusters=100,)\n",
    "\n",
    "labels = clusterer.predict(embeddings.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cebda6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7519d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ba85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate=1/chunks.step\n",
    "samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39953b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416ae85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration=librosa.get_duration(filename=\"D:/BraveDownloads/Jordan Peterson Confronts Australian Politician on Gender Politics and Quotas _ Q&A.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1347e2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa8c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelTime=[]\n",
    "i=0\n",
    "while i<len(labels):\n",
    "    start=i/2\n",
    "    while i+1<len(labels) and labels[i]==labels[i+1]:\n",
    "        i+=1\n",
    "    labelTime.append([labels[i],start,i/2+0.5])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b930d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labelTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cafea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labelTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee98bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct=partition.segments_list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d08bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25b4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_model_rbf = SpectralClustering(n_clusters = 2, affinity ='rbf')\n",
    "  \n",
    "# Training the model and Storing the predicted cluster labels\n",
    "labels_rbf = spectral_model_rbf.fit_predict(embeddings.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40663b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(labels==labels_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b37724",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelTime2=[]\n",
    "i=0\n",
    "while i<len(labels_rbf):\n",
    "    start=i/2\n",
    "    while i+1<len(labels_rbf) and labels_rbf[i]==labels_rbf[i+1]:\n",
    "        i+=1\n",
    "    labelTime2.append([labels_rbf[i],start,i/2+0.5])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c57fe7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labelTime2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95274c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labeling=[]\n",
    "j=0\n",
    "for i in labelTime:\n",
    "    print(i)\n",
    "    while j<len(ct) and ((ct[j].end<=i[2] and ct[j].end>=i[1])or()):\n",
    "        print(ct[j].start,ct[j].end,i[0])\n",
    "        labeling.append([ct[j].start,ct[j].end,i[0]])\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d6fe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff3ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358024aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfile = {'audio': \"D:/BraveDownloads/8q7vg-909qk.wav\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform = RawAudio(sample_rate=16000)(bfile).data\n",
    "display.Audio(data=waveform.squeeze(), rate=16000, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization = pipeline(bfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6252364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scd_scores = scd(bfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c2e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak = Peak(alpha=0.2, min_duration=0.05, log_scale=True)\n",
    "# speaker change point (as `pyannote.core.Timeline` instance)\n",
    "partition = peak.apply(scd_scores, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e881f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "scd_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36333b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7e6c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in partition.segments_list_:\n",
    "    audio, rate = librosa.load(\"D:/BraveDownloads/8q7vg-909qk.wav\", sr = 16000, offset=i.start, duration=i.end-i.start)\n",
    "    input_values = pro_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\", sampling_rate=rate).input_values\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            logits = pro_960h_model(input_values).logits\n",
    "        prediction = torch.argmax(logits, dim = -1)\n",
    "        transcription = pro_960h_processor.batch_decode(prediction)[0].lower()\n",
    "        print(\"\\\"\"+transcription+\"\\\"\" if transcription != None else \"[NOISE]\")\n",
    "    except:\n",
    "        print(\"[NOISE]\")\n",
    "        continue \n",
    "    display.display(display.Audio(data=audio.squeeze(), rate=16000, autoplay=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_scores = sad(bfile)\n",
    "\n",
    "# binarize raw SAD scores\n",
    "# NOTE: both onset/offset values were tuned on AMI dataset.\n",
    "# you might need to use different values for better results.\n",
    "from pyannote.audio.utils.signal import Binarize\n",
    "binarize = Binarize(offset=0.52, onset=0.52, log_scale=True, \n",
    "                    min_duration_off=0.1, min_duration_on=0.1)\n",
    "\n",
    "# speech regions (as `pyannote.core.Timeline` instance)\n",
    "speech = binarize.apply(sad_scores, dimension=1)\n",
    "\n",
    "emb = torch.hub.load('pyannote/pyannote-audio', 'emb_ami')\n",
    "speech_turns = partition.crop(speech)\n",
    "embeddings = emb(bfile)\n",
    "chunks = embeddings.sliding_window\n",
    "print(f'Embeddings were extracted every {1000 * chunks.step:g}ms on {1000 * chunks.duration:g}ms-long windows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe81f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "cosine(embeddings.data[0],embeddings.data[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a844152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linked = linkage(embeddings.data, 'complete')\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "dendrogram(linked)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e0de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(affinity='euclidean', linkage='complete')\n",
    "cluster.fit_predict(embeddings.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353452fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cluster.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac1758",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition.segments_list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba150cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration=librosa.get_duration(filename=\"D:/BraveDownloads/8q7vg-909qk.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10441cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc09ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_turns.segments_list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.core import Timeline\n",
    "turns = Timeline(segments=[s for s in speech_turns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe3a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecf9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Final_Turns=[],[]\n",
    "for segment in turns:\n",
    "    # \"strict\" only keeps embedding strictly included in segment\n",
    "    x = embeddings.crop(segment, mode='strict')\n",
    "    # average speech turn embedding\n",
    "    if len(x)>0:\n",
    "        X.append(np.mean(x, axis=0))\n",
    "        Final_Turns.append(segment)\n",
    "\n",
    "X = np.vstack(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4022590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dddf246",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(affinity='cosine', linkage='complete')\n",
    "cluster.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8511c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc579ad4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "j=0\n",
    "for i in partition.segments_list_:\n",
    "    audio, rate = librosa.load(\"D:/BraveDownloads/8q7vg-909qk.wav\", sr = 16000, offset=i.start, duration=i.end-i.start)\n",
    "    input_values = pro_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\", sampling_rate=rate).input_values\n",
    "    try:\n",
    "        if(i.intersects(Final_Turns[j])):\n",
    "            with torch.no_grad():\n",
    "                logits = pro_960h_model(input_values).logits\n",
    "            prediction = torch.argmax(logits, dim = -1)\n",
    "            transcription = pro_960h_processor.batch_decode(prediction)[0].lower()\n",
    "            print(\"Speaker \"+str(cluster.labels_[j]+1)+\" :  \"+parser.parse(p.punctuate(parser.parse(transcription)['result']))['result'] if transcription != None else \"[NOISE]\")\n",
    "            j+=1\n",
    "        else:\n",
    "            print(\"[NOISE/Overlapping Conversations]\")\n",
    "    except:\n",
    "        print(\"[NOISE/Overlapping Conversations]\")\n",
    "    display.display(display.Audio(data=audio.squeeze(), rate=16000, autoplay=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd91ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = Punctuator('D:/Study/Sem7/Final Year/.punctuator/INTERSPEECH-T-BRNN.pcl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a487d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "j=0\n",
    "last=0\n",
    "for i in partition.segments_list_:\n",
    "    try:\n",
    "        if(i.intersects(Final_Turns[j])):\n",
    "            audio, rate = librosa.load(\"D:/BraveDownloads/8q7vg-909qk.wav\", sr = 16000, offset=i.start, duration=i.end-i.start)\n",
    "            input_values = pro_960h_processor(audio, return_tensors=\"pt\", padding=\"longest\", sampling_rate=rate).input_values\n",
    "            with torch.no_grad():\n",
    "                logits = pro_960h_model(input_values).logits\n",
    "            prediction = torch.argmax(logits, dim = -1)\n",
    "            transcription = pro_960h_processor.batch_decode(prediction)[0].lower()\n",
    "            if j==0 or cluster.labels_[j]!=last:\n",
    "                print(\"Speaker \"+str(cluster.labels_[j]+1)+\" :  \"+parser.parse(p2.punctuate(parser.parse(transcription)['result']))['result'] if transcription != None else \"[NOISE]\")\n",
    "            else:\n",
    "                print(parser.parse(p2.punctuate(parser.parse(transcription)['result']))['result'] if transcription != None else \"[NOISE]\")\n",
    "            last=cluster.labels_[j]\n",
    "            j+=1\n",
    "        else:\n",
    "            print(\"[NOISE/Overlapping Conversations]\")\n",
    "            last=-1\n",
    "    except:\n",
    "        print(\"[NOISE/Overlapping Conversations]\")\n",
    "        last=-1\n",
    "    display.display(display.Audio(data=audio.squeeze(), rate=16000, autoplay=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2de79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
